{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models  \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm, trange\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\images\"\n",
    "    label_csv = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\labels.csv\"\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 60\n",
    "    lr = 5e-5  \n",
    "    num_workers = 0 \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = \"efficientnet_b0\"  \n",
    "    save_dir = \"./output\"\n",
    "    seed = 42\n",
    "\n",
    "torch.manual_seed(Config.seed)\n",
    "os.makedirs(Config.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d05810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df      = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.train   = train\n",
    "        \n",
    "        if self.train:\n",
    "            self.transform = get_transforms(train=True)\n",
    "        else:\n",
    "            self.transform = get_transforms(train=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row      = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        # 1) 读图并转成 numpy\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        # 2) 统一 transform\n",
    "        image = self.transform(image=image)['image']  # 已经是 Tensor, C×H×W\n",
    "        # 3) 取标签\n",
    "        label = int(row['label'])\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"\n",
    "    CutMix 随机生成一个矩形框。\n",
    "    size: tuple (W, H)\n",
    "    lam: 从 Beta 分布中采样的 λ\n",
    "    返回 (x0, y0, x1, y1)\n",
    "    \"\"\"\n",
    "    W, H = size\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # 随机中心\n",
    "    cx = random.randint(0, W)\n",
    "    cy = random.randint(0, H)\n",
    "\n",
    "    x0 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    y0 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    x1 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return x0, y0, x1, y1\n",
    "\n",
    "class MixUpCollator:\n",
    "    def __init__(self, alpha=0.4, prob=0.5):\n",
    "        \"\"\"\n",
    "        alpha: MixUp Beta 分布参数\n",
    "        prob: 每个 batch 应用 MixUp 的概率\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.prob  = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of (image_tensor, label)\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)                          # [B, C, H, W]\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).view(-1,1)  # [B, 1]\n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        idx = torch.randperm(images.size(0))\n",
    "        mixed_images = lam * images + (1. - lam) * images[idx]\n",
    "        mixed_labels = lam * labels + (1. - lam) * labels[idx]\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "class CutMixCollator:\n",
    "    def __init__(self, beta=1.0, prob=0.5):\n",
    "        \"\"\"\n",
    "        beta: CutMix Beta 分布参数\n",
    "        prob: 每个 batch 应用 CutMix 的概率\n",
    "        \"\"\"\n",
    "        self.beta = beta\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)                          \n",
    "        labels = torch.tensor(labels, dtype=torch.float32).view(-1,1)  \n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        idx = torch.randperm(images.size(0))\n",
    "\n",
    "        # 随机裁框\n",
    "        _, C, H, W = images.shape\n",
    "        x0, y0, x1, y1 = rand_bbox((W, H), lam)\n",
    "\n",
    "        images_cut = images.clone()\n",
    "        # 将第 i 张图的 (y0:y1, x0:x1) 区域替换为第 idx[i] 张图同区域\n",
    "        images_cut[:, :, y0:y1, x0:x1] = images[idx, :, y0:y1, x0:x1]\n",
    "\n",
    "        # 重新计算 λ：去掉的区域比例\n",
    "        area = (x1 - x0) * (y1 - y0)\n",
    "        lam_adj = 1. - area / (W * H)\n",
    "\n",
    "        mixed_labels = lam_adj * labels + (1. - lam_adj) * labels[idx]\n",
    "        return images_cut, mixed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channel, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        # 通道注意力\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "        # 空间注意力\n",
    "        self.conv_spatial = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 通道注意力\n",
    "        avg_out = self.mlp(self.avg_pool(x))\n",
    "        max_out = self.mlp(self.max_pool(x))\n",
    "        x = x * self.sigmoid_channel(avg_out + max_out)\n",
    "        # 空间注意力\n",
    "        avg_map = x.mean(dim=1, keepdim=True)\n",
    "        max_map, _ = x.max(dim=1, keepdim=True)\n",
    "        x = x * self.sigmoid_spatial(self.conv_spatial(torch.cat([avg_map, max_map], dim=1)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            # 用 size 参数取代 height & width\n",
    "            A.RandomResizedCrop(\n",
    "                size=(Config.img_size, Config.img_size),\n",
    "                scale=(0.8, 1.0),\n",
    "                ratio=(0.9, 1.1),\n",
    "                p=1.0\n",
    "            ),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.2),\n",
    "            A.ColorJitter(\n",
    "                brightness=0.2, contrast=0.2,\n",
    "                saturation=0.2, hue=0.1, p=0.5\n",
    "            ),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=8, max_height=16, max_width=16,\n",
    "                min_holes=1, min_height=8, min_width=8, p=0.3\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "            # 再保证输出尺寸\n",
    "            A.Resize(\n",
    "                height=Config.img_size,\n",
    "                width=Config.img_size\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(\n",
    "                height=Config.img_size,\n",
    "                width=Config.img_size\n",
    "            ),\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "class TumorClassifierCBAM(nn.Module):\n",
    "    def __init__(self, dropout_p=0.7):\n",
    "        super().__init__()\n",
    "        # 1) 预训练 EfficientNet-B0，不要它的分类头\n",
    "        backbone = models.efficientnet_b0(pretrained=True)\n",
    "        self.features = backbone.features  # [B,1280,H',W']\n",
    "        \n",
    "        # 2) 在主干最后插一个 CBAM\n",
    "        self.cbam = CBAM(channel=1280, reduction=16, kernel_size=7)\n",
    "        \n",
    "        # 3) 全局池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # 4) 分类头：BatchNorm1d -> Dropout -> Linear\n",
    "        in_feats = backbone.classifier[1].in_features  # =1280\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_feats),\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_feats, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)     # [B,1280,H',W']\n",
    "        x = self.cbam(x)         # 加入注意力机制\n",
    "        x = self.global_pool(x)  # [B,1280,1,1]\n",
    "        x = x.flatten(1)         # [B,1280]\n",
    "        x = self.classifier(x)   # [B,1]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    二分类 Focal Loss.\n",
    "    logits: 网络原始输出，shape [B,1] 或 [B]\n",
    "    targets: 0/1 标签，shape [B,1] 或 [B]\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, alpha=0.25, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # flatten\n",
    "        if logits.dim()>1:\n",
    "            logits = logits.view(-1)\n",
    "        targets = targets.view(-1).float()\n",
    "        # 1) 先算 BCE\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        probas  = torch.sigmoid(logits)\n",
    "        # 2) p_t\n",
    "        p_t = probas * targets + (1 - probas) * (1 - targets)\n",
    "        # 3) α 平衡因子\n",
    "        alpha_factor = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        # 4) (1−p_t)^γ\n",
    "        modulating_factor = (1 - p_t).pow(self.gamma)\n",
    "        loss = alpha_factor * modulating_factor * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images = images.to(Config.device)\n",
    "\n",
    "        labels = labels.to(Config.device).float()\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)  # 只在 [B] -> [B,1] 时加这一维\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)        # [B,1]\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ac11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(Config.device)\n",
    "            labels = labels.to(Config.device).float()\n",
    "            if labels.dim() == 1:\n",
    "                labels = labels.unsqueeze(1)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss   = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_preds.extend(probs)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(loader), np.array(all_preds).ravel(), np.array(all_labels).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取 CSV 标签\n",
    "full_df = pd.read_csv(Config.label_csv)\n",
    "\n",
    "# 三分法划分 train / val / test\n",
    "train_df, tmp_df = train_test_split(\n",
    "    full_df,\n",
    "    test_size=0.3,\n",
    "    stratify=full_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=tmp_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "\n",
    "print(f\"训练集类别分布：\\n{train_df['label'].value_counts()}\")\n",
    "print(f\"验证集类别分布：\\n{val_df['label'].value_counts()}\")\n",
    "print(f\"测试集类别分布：\\n{test_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27f37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_mix_mode = \"cutmix\"  # 可选: \"none\", \"mixup\", \"cutmix\"\n",
    "if use_mix_mode.lower() == \"cutmix\":\n",
    "    collate_fn = CutMixCollator(beta=1.0, prob=0.5)\n",
    "    shuffle_train = False\n",
    "elif use_mix_mode.lower() == \"mixup\":\n",
    "    collate_fn = MixUpCollator(alpha=0.4, prob=0.5)\n",
    "    shuffle_train = False\n",
    "else:\n",
    "    collate_fn = None\n",
    "    shuffle_train = True\n",
    "\n",
    "print(f\"Mix mode={use_mix_mode}, shuffle_train={shuffle_train}\")\n",
    "\n",
    "# 构建 Dataset\n",
    "train_dataset = TumorDataset(train_df, Config.data_dir, train=True)\n",
    "val_dataset   = TumorDataset(val_df,   Config.data_dir, train=False)\n",
    "test_dataset  = TumorDataset(test_df,  Config.data_dir, train=False)\n",
    "\n",
    "# 构建 DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# 在构建 train_loader 之前，加一段计算每个样本权重的代码：\n",
    "class_counts = train_df['label'].value_counts().to_dict()  \n",
    "# e.g. {0: 9000, 1: 1000}\n",
    "weights = train_df['label'].map(lambda x: 1.0 / class_counts[x]).values\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "# 然后把 train_loader 改成：\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,            # 用 sampler 时不要再 shuffle\n",
    "    sampler=sampler,\n",
    "    num_workers=Config.num_workers,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "\n",
    "# 初始化模型\n",
    "print(\"初始化模型中...\")\n",
    "model = TumorClassifierCBAM(dropout_p=0.8).to(Config.device)\n",
    "print(\"模型初始化完成\")\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=Config.lr,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_f1': []}\n",
    "best_auc = 0\n",
    "best_thresh = 0.5  # 会在训练中更新\n",
    "\n",
    "# 显示训练集类别分布\n",
    "train_labels = train_df['label']\n",
    "print(f\"当前训练集图像分布：正常类 {(train_labels == 0).sum()}，肿瘤类 {(train_labels == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a336c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —— 训练循环：只用 Val AUC 早停，不在每轮中做阈值搜索 —— \n",
    "\n",
    "best_auc     = 0.0\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{Config.epochs}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, preds, targets = evaluate(model, val_loader, criterion)\n",
    "    val_auc = roc_auc_score(targets, preds)\n",
    "\n",
    "    # 打印指标（仅用 AUC 评估）\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "\n",
    "    # 保存最优模型（按 AUC）\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), os.path.join(Config.save_dir, \"best_model.pth\"))\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "    # 早停检查（监控 AUC）\n",
    "    early_stopper(val_auc)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# —— 训练结束后，再做一次整体阈值搜素 & 最终评估 —— \n",
    "\n",
    "# 加载最佳模型权重\n",
    "model.load_state_dict(torch.load(os.path.join(Config.save_dir, \"best_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# 在整个验证集上计算概率\n",
    "_, preds, targets = evaluate(model, val_loader, criterion)\n",
    "preds = preds.ravel()\n",
    "targets = targets.ravel()\n",
    "\n",
    "# 搜索最佳 F1 阈值\n",
    "best_f1, best_thresh = 0.0, 0.5\n",
    "for t in np.arange(0.1, 0.9, 0.01):\n",
    "    f1 = f1_score(targets, (preds >= t).astype(int))\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_thresh = f1, t\n",
    "\n",
    "# 最终按最佳阈值计算指标\n",
    "final_preds = (preds >= best_thresh).astype(int)\n",
    "final_acc  = accuracy_score(targets, final_preds)\n",
    "final_auc  = roc_auc_score(targets, preds)\n",
    "tn, fp, fn, tp = confusion_matrix(targets, final_preds).ravel()\n",
    "final_spec = tn/(tn+fp)\n",
    "final_sens = tp/(tp+fn)\n",
    "\n",
    "print(\"\\n=== 最终验证集评估 ===\")\n",
    "print(f\"Best F1 Threshold: {best_thresh:.2f}\")\n",
    "print(f\"ACC:         {final_acc:.4f}\")\n",
    "print(f\"F1-score:    {best_f1:.4f}\")\n",
    "print(f\"AUC:         {final_auc:.4f}\")\n",
    "print(f\"Specificity: {final_spec:.4f}\")\n",
    "print(f\"Sensitivity: {final_sens:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc04711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# —— 在三分法划分后加入以下检查 —— \n",
    "train_files = set(train_df['filename'].tolist())\n",
    "val_files   = set(val_df  ['filename'].tolist())\n",
    "test_files  = set(test_df ['filename'].tolist())\n",
    "\n",
    "# 检查两两交集是否为空\n",
    "assert train_files.isdisjoint(val_files),  \\\n",
    "    f\"数据泄露：train 与 val 有 {len(train_files & val_files)} 张图重复\"\n",
    "assert train_files.isdisjoint(test_files), \\\n",
    "    f\"数据泄露：train 与 test 有 {len(train_files & test_files)} 张图重复\"\n",
    "assert val_files.isdisjoint(test_files),   \\\n",
    "    f\"数据泄露：val   与 test 有 {len(val_files & test_files)} 张图重复\"\n",
    "\n",
    "print(\"划分校验通过，train/val/test 三个集合互不重叠。\")\n",
    "\n",
    "# 手动设置路径和参数\n",
    "label_csv = r\"D:\\Leko\\medical_model\\task1\\dataset\\labels.csv\"\n",
    "img_dir   = r\"D:\\Leko\\medical_model\\task1\\dataset\\images\"\n",
    "seed = 42\n",
    "\n",
    "# 1. 读取标签并去重\n",
    "df = pd.read_csv(label_csv).drop_duplicates(subset=['filename'])\n",
    "\n",
    "# 2. 三分法划分\n",
    "train_df, tmp_df = train_test_split(\n",
    "    df, test_size=0.3, stratify=df['label'], random_state=seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df, test_size=0.5, stratify=tmp_df['label'], random_state=seed\n",
    ")\n",
    "\n",
    "# 3. 定义显示函数\n",
    "def show_samples(df, name):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    for ax, label in zip(axes, [0, 1]):\n",
    "        subset = df[df['label'] == label]\n",
    "        fname = random.choice(subset['filename'].tolist())\n",
    "        img = Image.open(os.path.join(img_dir, fname)).convert('RGB')\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{name} label={label}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. 显示三个集合的样本\n",
    "show_samples(train_df, \"Train\")\n",
    "show_samples(val_df, \"Val\")\n",
    "show_samples(test_df, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load(os.path.join(Config.save_dir, \"best_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# 在测试集上评估\n",
    "test_loss, test_preds, test_targets = evaluate(model, test_loader, criterion)\n",
    "test_auc  = roc_auc_score(test_targets, test_preds)\n",
    "test_f1   = f1_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "test_acc  = accuracy_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "\n",
    "# 计算混淆矩阵并提取指标\n",
    "cm = confusion_matrix(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn + 1e-8)  # True Positive Rate\n",
    "specificity = tn / (tn + fp + 1e-8)  # True Negative Rate\n",
    "\n",
    "# 打印所有指标\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test AUC: {test_auc:.4f} | \"\n",
    "      f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "print(f\"Test Sensitivity (Recall for tumor): {sensitivity:.4f} | \"\n",
    "      f\"Test Specificity (Recall for normal): {specificity:.4f}\")\n",
    "\n",
    "# 绘制测试集混淆矩阵\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal\", \"Tumor\"],\n",
    "            yticklabels=[\"Normal\", \"Tumor\"])\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# 保存测试集预测结果\n",
    "test_df = test_df.copy()\n",
    "test_df['pred_prob']  = test_preds\n",
    "test_df['pred_label'] = (test_preds >= best_thresh).astype(int)\n",
    "test_df.to_csv(os.path.join(Config.save_dir, \"test_predictions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正确显示负号\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"./output/best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "infer_transform = get_transforms(train=False)\n",
    "\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Apply transform\n",
    "    transformed = infer_transform(image=image_np)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(Config.device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        label = 1 if prob >= 0.5 else 0\n",
    "\n",
    "    # 可视化\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"预测标签: {'肿瘤' if label==1 else '正常'}\\n预测概率: {prob:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "predict_image(\"D:\\\\Leko\\\\test1.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test2.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test3.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test4.jpg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 外部验证集评估 — 带去黑边 & 居中补齐预处理\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# —— 新增：去黑边 + 居中补齐预处理函数 —— \n",
    "def preprocess_image(img: Image.Image) -> Image.Image:\n",
    "    # 1) 转为 numpy 判断哪儿全黑\n",
    "    arr = np.array(img)\n",
    "    if arr.ndim == 3:\n",
    "        mask = np.any(arr != arr[0,0,:], axis=2)\n",
    "    else:\n",
    "        mask = arr != arr[0,0]\n",
    "    coords = np.argwhere(mask)\n",
    "    if coords.size:\n",
    "        y0, x0 = coords.min(axis=0)\n",
    "        y1, x1 = coords.max(axis=0)\n",
    "        img = img.crop((x0, y0, x1 + 1, y1 + 1))\n",
    "    # 2) 居中 pad 成正方形\n",
    "    w, h = img.size\n",
    "    max_wh = max(w, h)\n",
    "    pad_w = (max_wh - w) // 2\n",
    "    pad_h = (max_wh - h) // 2\n",
    "    padding = (pad_w, pad_h, max_wh - w - pad_w, max_wh - h - pad_h)\n",
    "    img = ImageOps.expand(img, padding, fill=0)\n",
    "    return img\n",
    "\n",
    "# 1. 配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ext_root = r'D:\\Leko\\testset\\testset1(8)'\n",
    "best_model_path = os.path.join(Config.save_dir, \"best_model.pth\")\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "# 2. 预处理（加上 preprocess_image）\n",
    "ext_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: preprocess_image(img)),  # ← 新增\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485,0.456,0.406),\n",
    "                         std=(0.229,0.224,0.225)),\n",
    "])\n",
    "\n",
    "# 3. 构建 DataLoader\n",
    "ext_dataset = ImageFolder(root=ext_root, transform=ext_transform)\n",
    "print(\"External classes:\", ext_dataset.classes)\n",
    "ext_loader = DataLoader(\n",
    "    ext_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "print(f\"外部验证集: {len(ext_dataset)} 张图, {len(ext_loader)} 个 batch\")\n",
    "\n",
    "# 4. 初始化模型并加载权重\n",
    "model = TumorClassifierCBAM(dropout_p=0.8).to(Config.device)\n",
    "state = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print(\"Loaded best_model.pth\")\n",
    "# %% [markdown]\n",
    "# ## 外部验证集评估 — 展示每个 label 下 3 张经过 transform 的图像\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# 先从 ext_dataset 里各抽 3 张\n",
    "samples_per_class = {0: [], 1: []}\n",
    "indices = list(range(len(ext_dataset)))\n",
    "random.shuffle(indices)\n",
    "for idx in indices:\n",
    "    img, label = ext_dataset[idx]  # 已经做了 preprocess + Resize + ToTensor + Normalize\n",
    "    if len(samples_per_class[label]) < 3:\n",
    "        samples_per_class[label].append(img)\n",
    "    if len(samples_per_class[0]) == 3 and len(samples_per_class[1]) == 3:\n",
    "        break\n",
    "\n",
    "# 定义一个反归一化，用于可视化\n",
    "inv_norm = transforms.Normalize(\n",
    "    mean=[-m/s for m,s in zip((0.485,0.456,0.406),(0.229,0.224,0.225))],\n",
    "    std=[1/s for s in (0.229,0.224,0.225)]\n",
    ")\n",
    "\n",
    "# 绘图\n",
    "fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for cls, row in samples_per_class.items():\n",
    "    for i, tensor_img in enumerate(row):\n",
    "        img_vis = inv_norm(tensor_img)                 # 先反归一化\n",
    "        img_vis = img_vis.permute(1,2,0).clamp(0,1)    # HWC\n",
    "        axes[cls, i].imshow(img_vis.numpy())\n",
    "        axes[cls, i].set_title(f\"label={cls}\")\n",
    "        axes[cls, i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. 推理\n",
    "all_probs, all_labels = [], []\n",
    "with torch.inference_mode():\n",
    "    for imgs, labels in tqdm(ext_loader, desc=\"External Inference\"):\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        logits = model(imgs).view(-1)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_probs  = np.array(all_probs)\n",
    "all_labels = np.array(all_labels).astype(int)\n",
    "\n",
    "# 6. 计算并打印指标\n",
    "preds = (all_probs >= 0.5).astype(int)\n",
    "acc  = accuracy_score(all_labels, preds)\n",
    "f1   = f1_score(all_labels, preds)\n",
    "auc  = roc_auc_score(all_labels, all_probs)\n",
    "tn, fp, fn, tp = confusion_matrix(all_labels, preds).ravel()\n",
    "spec = tn / (tn + fp)\n",
    "sens = tp / (tp + fn)\n",
    "\n",
    "print(\"\\n=== 外部验证集评估结果 ===\")\n",
    "print(f\"样本总数: {len(ext_dataset)} \"\n",
    "      f\"(normal={ext_dataset.targets.count(0)}, tumor={ext_dataset.targets.count(1)})\")\n",
    "print(f\"ACC:         {acc:.4f}\")\n",
    "print(f\"F1-score:    {f1:.4f}\")\n",
    "print(f\"AUC:         {auc:.4f}\")\n",
    "print(f\"Specificity: {spec:.4f}\")\n",
    "print(f\"Sensitivity: {sens:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
