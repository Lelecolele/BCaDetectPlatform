{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import models  \n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm, trange\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\images\"\n",
    "    label_csv = \"D:\\\\Leko\\\\medical_model\\\\task1\\\\dataset\\\\labels.csv\"\n",
    "    img_size = 224\n",
    "    batch_size = 32\n",
    "    epochs = 30\n",
    "    lr = 1e-4 \n",
    "    num_workers = 0  \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = \"vit_base_patch16_224\"  \n",
    "    save_dir = \"./output\"\n",
    "    seed = 42\n",
    "\n",
    "torch.manual_seed(Config.seed)\n",
    "os.makedirs(Config.save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d05810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        label = int(row['label'])\n",
    "\n",
    "\n",
    "        if self.train:\n",
    "            transform = get_transforms(train=True, is_tumor=(label == 1))\n",
    "        else:\n",
    "            transform = get_transforms(train=False)\n",
    "\n",
    "        image = transform(image=image)['image']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutMixCollator:\n",
    "    def __init__(self, beta=1.0, prob=0.5):\n",
    "        self.beta = beta\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        labels = torch.tensor(labels).float().view(-1, 1)  \n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        batch_size = images.size(0)\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "        mixed_images = lam * images + (1 - lam) * images[index]\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels[index]\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "\n",
    "\n",
    "class MixUpCollator:\n",
    "    def __init__(self, alpha=0.4, prob=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images, labels = zip(*batch)\n",
    "        images = torch.stack(images)\n",
    "        labels = torch.tensor(labels).float().view(-1, 1)\n",
    "\n",
    "\n",
    "        if np.random.rand() > self.prob:\n",
    "            return images, labels\n",
    "\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        index = torch.randperm(images.size(0))\n",
    "        mixed_images = lam * images + (1 - lam) * images[index]\n",
    "        labels = lam * labels + (1 - lam) * labels[index]\n",
    "        return mixed_images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d795a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True, is_tumor=False):\n",
    "    if train:\n",
    "        base = [\n",
    "            A.Resize(Config.img_size, Config.img_size),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "        ]\n",
    "        if is_tumor:\n",
    "            base += [\n",
    "                A.RandomBrightnessContrast(p=0.5),\n",
    "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=30, p=0.3),\n",
    "                A.CoarseDropout(p=0.3)\n",
    "            ]\n",
    "        base += [\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "        return A.Compose(base)\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(Config.img_size, Config.img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "class TumorClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1) 从 timm 加载 ViT-Base 干骨干，不带最后 head\n",
    "        self.backbone = timm.create_model(\n",
    "            Config.model_name,   # \"vit_base_patch16_224\"\n",
    "            pretrained=True,\n",
    "            num_classes=0,       # 只输出特征，不要原始分类头\n",
    "            global_pool=\"avg\"    # 全局平均池化，输出 [B, C]\n",
    "        )\n",
    "        in_feats = self.backbone.num_features  # ViT-base 的隐藏维度通常是 768\n",
    "\n",
    "        # 2) 简单的线性分类头：从 [B, C] 到 [B, 1]\n",
    "        self.classifier = nn.Linear(in_feats, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)       # [B, 768]\n",
    "        out   = self.classifier(feats) # [B, 1]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return focal_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d5f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader):\n",
    "        images = images.to(Config.device)\n",
    "        labels = labels.float().unsqueeze(1).to(Config.device)  # [B,1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)        # [B,1]\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ac11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(Config.device)\n",
    "            labels = labels.float().unsqueeze(1).to(Config.device)  # 已正确处理\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images)    # [B,1]\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds.extend(probs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "    return total_loss / len(loader), np.array(preds), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cc4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_score\n",
    "        elif val_score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a336c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取 CSV 标签\n",
    "full_df = pd.read_csv(Config.label_csv)\n",
    "\n",
    "# 三分法划分 train / val / test\n",
    "train_df, tmp_df = train_test_split(\n",
    "    full_df,\n",
    "    test_size=0.3,\n",
    "    stratify=full_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    tmp_df,\n",
    "    test_size=0.5,\n",
    "    stratify=tmp_df['label'],\n",
    "    random_state=Config.seed\n",
    ")\n",
    "\n",
    "print(f\"训练集类别分布：\\n{train_df['label'].value_counts()}\")\n",
    "print(f\"验证集类别分布：\\n{val_df['label'].value_counts()}\")\n",
    "print(f\"测试集类别分布：\\n{test_df['label'].value_counts()}\")\n",
    "\n",
    "# 设置增强策略：baseline 不使用 CutMix/MixUp\n",
    "use_mix_mode = \"none\"\n",
    "collate_fn = None\n",
    "\n",
    "# Baseline 下直接随机打乱，不使用加权采样\n",
    "sampler = None\n",
    "\n",
    "# 构建 Dataset 和 DataLoader\n",
    "train_dataset = TumorDataset(train_df, Config.data_dir, train=True)\n",
    "val_dataset   = TumorDataset(val_df,   Config.data_dir, train=False)\n",
    "test_dataset  = TumorDataset(test_df,  Config.data_dir, train=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.num_workers\n",
    ")\n",
    "\n",
    "# 初始化模型\n",
    "print(\"初始化模型中...\")\n",
    "model = TumorClassifier().to(Config.device)\n",
    "print(\"模型初始化完成\")\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=Config.lr,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "early_stopper = EarlyStopping(patience=5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_f1': []}\n",
    "best_auc = 0\n",
    "best_thresh = 0.5  # 会在训练中更新\n",
    "\n",
    "# 显示训练集类别分布\n",
    "train_labels = train_df['label']\n",
    "print(f\"当前训练集图像分布：正常类 {(train_labels == 0).sum()}，肿瘤类 {(train_labels == 1).sum()}\")\n",
    "\n",
    "for epoch in range(Config.epochs):\n",
    "    print(f\"\\n📘 Epoch {epoch+1}/{Config.epochs}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, preds, targets = evaluate(model, val_loader, criterion)\n",
    "    val_auc = roc_auc_score(targets, preds)\n",
    "\n",
    "    # 最佳 F1 阈值搜索\n",
    "    val_f1_default = f1_score(targets, (preds >= 0.5).astype(int))\n",
    "    curr_best_f1, curr_best_thresh = 0, 0.5\n",
    "    for t in np.arange(0.1, 0.9, 0.01):\n",
    "        f1 = f1_score(targets, (preds >= t).astype(int))\n",
    "        if f1 > curr_best_f1:\n",
    "            curr_best_f1, curr_best_thresh = f1, t\n",
    "    best_thresh = curr_best_thresh\n",
    "    preds_bin = (preds >= best_thresh).astype(int)\n",
    "\n",
    "    # 打印指标\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | AUC: {val_auc:.4f}\")\n",
    "    print(f\"F1@0.50: {val_f1_default:.4f} | Best F1@{best_thresh:.2f}: {curr_best_f1:.4f}\")\n",
    "    print(f\" Accuracy: {accuracy_score(targets, preds_bin):.4f}\")\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(targets, preds_bin).ravel()\n",
    "    print(f\"Sensitivity (Recall for tumor): {tp/(tp+fn+1e-8):.4f}\")\n",
    "    print(f\" Specificity (Recall for normal): {tn/(tn+fp+1e-8):.4f}\")\n",
    "\n",
    "    # 记录历史\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    history['val_f1'].append(curr_best_f1)\n",
    "\n",
    "    # 保存最优模型\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), os.path.join(Config.save_dir, \"best_model.pth\"))\n",
    "        with open(os.path.join(Config.save_dir, \"best_thresh.txt\"), 'w') as f:\n",
    "            f.write(f\"{best_thresh:.2f}\")\n",
    "        print(\"Best model saved.\")\n",
    "\n",
    "    # 早停检查\n",
    "    early_stopper(val_auc)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'],   label='Val Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_auc'], label='Val AUC')\n",
    "plt.title(\"Validation AUC\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(confusion_matrix(targets, preds_bin), annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal\",\"Tumor\"], yticklabels=[\"Normal\",\"Tumor\"])\n",
    "plt.title(\"Val Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 保存验证集预测\n",
    "val_df = val_df.copy()\n",
    "val_df['pred_prob']  = preds\n",
    "val_df['pred_label'] = preds_bin\n",
    "val_df.to_csv(os.path.join(Config.save_dir, \"val_predictions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load(os.path.join(Config.save_dir, \"best_model.pth\")))\n",
    "model.eval()\n",
    "\n",
    "# 在测试集上评估\n",
    "test_loss, test_preds, test_targets = evaluate(model, test_loader, criterion)\n",
    "test_auc  = roc_auc_score(test_targets, test_preds)\n",
    "test_f1   = f1_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "test_acc  = accuracy_score(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "\n",
    "# 计算混淆矩阵并提取指标\n",
    "cm = confusion_matrix(test_targets, (test_preds >= best_thresh).astype(int))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "sensitivity = tp / (tp + fn + 1e-8)  # True Positive Rate\n",
    "specificity = tn / (tn + fp + 1e-8)  # True Negative Rate\n",
    "\n",
    "# 打印所有指标\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test AUC: {test_auc:.4f} | \"\n",
    "      f\"Test F1: {test_f1:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "print(f\"Test Sensitivity (Recall for tumor): {sensitivity:.4f} | \"\n",
    "      f\"Test Specificity (Recall for normal): {specificity:.4f}\")\n",
    "\n",
    "# 绘制测试集混淆矩阵\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Normal\", \"Tumor\"],\n",
    "            yticklabels=[\"Normal\", \"Tumor\"])\n",
    "plt.title(\"Test Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# 保存测试集预测结果\n",
    "test_df = test_df.copy()\n",
    "test_df['pred_prob']  = test_preds\n",
    "test_df['pred_label'] = (test_preds >= best_thresh).astype(int)\n",
    "test_df.to_csv(os.path.join(Config.save_dir, \"test_predictions.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f51f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 正确显示负号\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"D:\\\\Leko\\\\medical_model\\\\task1\\\\output\\\\best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "infer_transform = get_transforms(train=False)\n",
    "\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    # Apply transform\n",
    "    transformed = infer_transform(image=image_np)\n",
    "    input_tensor = transformed['image'].unsqueeze(0).to(Config.device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        label = 1 if prob >= 0.5 else 0\n",
    "\n",
    "    # 可视化\n",
    "    plt.imshow(image_np)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"预测标签: {'肿瘤' if label==1 else '正常'}\\n预测概率: {prob:.4f}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "predict_image(\"D:\\\\Leko\\\\test1.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test2.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test3.jpg\")\n",
    "predict_image(\"D:\\\\Leko\\\\test4.jpg\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
